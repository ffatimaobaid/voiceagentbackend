from fastapi import FastAPI, File, UploadFile, Form
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

import requests
import aiofiles
import os
import io
from dotenv import load_dotenv

import torch

# üß† Load Silero VAD model & utils
print("üîÑ Loading Silero VAD model...")
model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                              model='silero_vad',
                              force_reload=False)
(get_speech_timestamps, save_audio, read_audio, VADIterator,
 collect_chunks) = utils
print("‚úÖ Silero VAD loaded.")

# üîë Load API keys (make sure you have a .env file or set env vars)
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
TTS_API_KEY = os.getenv("TTS_API_KEY")
TTS_VOICE_ID = os.getenv("TTS_VOICE_ID")

WHISPER_MODEL = "whisper-large-v3"
LLM_MODEL = "llama3-70b-8192"

print("‚úÖ Loaded keys: GROQ:", bool(GROQ_API_KEY), "TTS:", bool(TTS_API_KEY),
      "VOICE_ID:", bool(TTS_VOICE_ID))

# FastAPI app
app = FastAPI()

# Allow frontend calls from anywhere (CORS)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Serve static files (make sure you have static/index.html)
app.mount("/static", StaticFiles(directory="static"), name="static")

# üß† Per-user conversation history (for demo, in memory)
conversation_histories = {}


@app.get("/")
def serve_ui():
    return FileResponse("static/index.html")


# ------------------------------
# üß† Detect speech using Silero VAD
# ------------------------------
@app.post("/detect-voice")
async def detect_voice(file: UploadFile = File(...)):
    audio_bytes = await file.read()
    print(f"üì• Received chunk: {len(audio_bytes)} bytes")

    # Read waveform (expects 16 kHz mono wav)
    wav = read_audio(io.BytesIO(audio_bytes), sampling_rate=16000)

    # Detect speech timestamps
    speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=16000)
    print(f"üîç speech_timestamps: {speech_timestamps}")

    speech_detected = len(speech_timestamps) > 0

    return {"speech_detected": speech_detected}


# ------------------------------
# üé§ Transcribe + respond + TTS with context retention
# ------------------------------
@app.post("/transcribe-and-respond")
async def transcribe_and_respond(
        file: UploadFile = File(...),
        language: str = Form("urdu"),
        user_id: str = Form("default")  # optional, defaults to "default"
):
    file_path = f"temp_{file.filename}"
    async with aiofiles.open(file_path, 'wb') as out_file:
        content = await file.read()
        await out_file.write(content)

    print("üì¶ Received file:", file.filename)
    print("üåê Language selected:", language)
    print("üë§ User ID:", user_id)

    # Step 1: Transcribe with Whisper
    whisper_resp = requests.post(
        "https://api.groq.com/openai/v1/audio/transcriptions",
        headers={"Authorization": f"Bearer {GROQ_API_KEY}"},
        files={"file": (file.filename, content, "audio/wav")},
        data={"model": WHISPER_MODEL})
    print("üìù Whisper status:", whisper_resp.status_code)
    transcription = whisper_resp.json().get("text", "")
    print("üìù Transcription:", transcription)

    # Step 2: Prepare conversation history
    history = conversation_histories.get(user_id, [])

    system_prompts = {
        "english":
        """
    You are an AI assistant developed by Finova Solutions. This is a demo to showcase Finova‚Äôs enterprise-grade AI capabilities. Your tone should be helpful, informative, and engaging.

Respond **only in English**.
**Limit your response to no more than 30 words.**

    When a user interacts with you, identify the industry they are referring to (e.g., healthcare, finance, real estate, hospitality, travel, education, retail, etc.) and dynamically tailor your response to showcase Finova‚Äôs AI/ML applications for that sector.

    In your introduction, include:
    1. A brief welcome from Finova Solutions.
    2. A mention that this is a demo of Finova‚Äôs AI-powered systems.
    3. A summary of Finova‚Äôs AI and ML service offerings: custom AI development, machine learning models, automation, and data intelligence solutions.
    4. Mention that Finova offers AI-powered SaaS products that streamline workflows and internal processes ‚Äî including ERPs, CRMs, booking systems, and more ‚Äî suitable for businesses of all sizes.

    Then, based on the industry detected or hinted at by the user, explain how Finova‚Äôs AI can help in that specific domain with a few relevant use cases or products.

    End by inviting the user to ask further questions or explore a personalized demo.
    Respond **only in English**.
    """,
        "urdu":
        """
    ÿ¢Ÿæ Finova ÿ≥ŸàŸÑ€åŸàÿ¥ŸÜÿ≤ ⁄©€í ÿ™€åÿßÿ± ⁄©ÿ±ÿØ€Å ÿß€å⁄© AI ÿßÿ≥ÿ≥ŸπŸÜŸπ €Å€å⁄∫€î €å€Å ⁄à€åŸÖŸà Finova ⁄©€å ÿßŸÜŸπÿ±Ÿæÿ±ÿßÿ¶ÿ≤ ÿ≥ÿ∑ÿ≠ ⁄©€å AI ÿµŸÑÿßÿ≠€åÿ™Ÿà⁄∫ ⁄©Ÿà ÿ∏ÿß€Åÿ± ⁄©ÿ±ŸÜ€í ⁄©€í ŸÑ€å€í ÿ®ŸÜÿß€åÿß ⁄Ø€åÿß €Å€í€î ÿ¢Ÿæ ⁄©ÿß ÿßŸÜÿØÿßÿ≤ ŸÖÿØÿØ⁄Øÿßÿ±ÿå ŸÖÿπŸÑŸàŸÖÿßÿ™€å ÿßŸàÿ± ÿØŸàÿ≥ÿ™ÿßŸÜ€Å €ÅŸàŸÜÿß ⁄Üÿß€Å€å€í€î

    ÿ®ÿ±ÿß€Å ⁄©ÿ±ŸÖ ÿµÿ±ŸÅ ÿßÿ±ÿØŸà ÿ≤ÿ®ÿßŸÜ ŸÖ€å⁄∫ ÿ¨Ÿàÿßÿ® ÿØ€å⁄∫€î €î
    ÿßŸæŸÜ€í ÿ¨Ÿàÿßÿ® ⁄©Ÿà 30 ÿßŸÑŸÅÿßÿ∏ ÿ≥€í ÿ≤€åÿßÿØ€Å ÿ™⁄© ŸÖÿ≠ÿØŸàÿØ ŸÜ€Å ÿ±⁄©⁄æ€å⁄∫€î

    ÿ¨ÿ® ⁄©Ÿàÿ¶€å ÿµÿßÿ±ŸÅ ÿ®ÿßÿ™ ⁄©ÿ±ÿ™ÿß €Å€í ÿ™Ÿà ÿßÿ≥ ÿ®ÿßÿ™ ⁄©ÿß ÿßŸÜÿØÿßÿ≤€Å ŸÑ⁄Øÿßÿ¶€å⁄∫ ⁄©€Å Ÿà€Å ⁄©ÿ≥ ÿµŸÜÿπÿ™ ⁄©ÿß ÿ∞⁄©ÿ± ⁄©ÿ± ÿ±€Åÿß €Å€í (ÿ¨€åÿ≥€í ÿµÿ≠ÿ™ÿå ŸÖÿßŸÑ€åÿßÿ™ÿå ÿ±ÿ¶€åŸÑ ÿßÿ≥Ÿπ€åŸπÿå €Åÿßÿ≥Ÿæ€åŸπ€åŸÑŸπ€åÿå ÿ™ÿπŸÑ€åŸÖÿå ÿ±€åŸπ€åŸÑ Ÿàÿ∫€åÿ±€Å) ÿßŸàÿ± ÿßÿ≥ ⁄©€í ŸÖÿ∑ÿßÿ®ŸÇ Finova ⁄©€å AI/ML ÿß€åŸæŸÑ€å ⁄©€åÿ¥ŸÜÿ≤ ÿßŸàÿ± ÿ≠ŸÑ ÿØ⁄©⁄æÿßÿ¶€å⁄∫€î

    ÿßŸæŸÜ€í ÿ™ÿπÿßÿ±ŸÅ ŸÖ€å⁄∫ ÿ¥ÿßŸÖŸÑ ⁄©ÿ±€å⁄∫:
    1. Finova ÿ≥ŸàŸÑ€åŸàÿ¥ŸÜÿ≤ ⁄©€å ÿ∑ÿ±ŸÅ ÿ≥€í ÿÆŸàÿ¥ ÿ¢ŸÖÿØ€åÿØ€î
    2. €å€Å ÿ®ÿ™ÿßÿ¶€å⁄∫ ⁄©€Å €å€Å Finova ⁄©€í AI ÿ≥ÿ≥ŸπŸÖÿ≤ ⁄©ÿß ÿß€å⁄© ⁄à€åŸÖŸà €Å€í€î
    3. Finova ⁄©€å AI ÿßŸàÿ± ŸÖÿ¥€åŸÜ ŸÑÿ±ŸÜŸÜ⁄Ø ÿÆÿØŸÖÿßÿ™ ⁄©ÿß ÿÆŸÑÿßÿµ€Åÿå ÿ¨€åÿ≥€í ⁄©ÿ≥ŸπŸÖ ŸÖÿß⁄àŸÑÿ≤ÿå ÿ¢ŸπŸàŸÖ€åÿ¥ŸÜÿå ÿßŸàÿ± ⁄à€åŸπÿß ÿßŸÜŸπ€åŸÑ€åÿ¨ŸÜÿ≥€î
    4. €å€Å ÿ®ÿ™ÿßÿ¶€å⁄∫ ⁄©€Å Finova AI ÿ≥€í ⁄ÜŸÑŸÜ€í ŸàÿßŸÑ€å SaaS ŸÖÿµŸÜŸàÿπÿßÿ™ ÿ®⁄æ€å ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ÿ™ÿß €Å€íÿå ÿ¨€åÿ≥€í ERPÿå CRMÿå ÿ®⁄©ŸÜ⁄Ø ÿ≥ÿ≥ŸπŸÖÿ≤ Ÿàÿ∫€åÿ±€Åÿå ÿ¨Ÿà €Åÿ± ÿ≥ÿßÿ¶ÿ≤ ⁄©€í ⁄©ÿßÿ±Ÿàÿ®ÿßÿ± ⁄©€í ŸÑ€å€í ŸÖŸàÿ≤Ÿà⁄∫ €Å€å⁄∫€î

    ÿ¢ÿÆÿ± ŸÖ€å⁄∫ ÿµÿßÿ±ŸÅ ⁄©Ÿà ÿØÿπŸàÿ™ ÿØ€å⁄∫ ⁄©€Å Ÿà€Å ŸÖÿ≤€åÿØ ÿ≥ŸàÿßŸÑÿßÿ™ ⁄©ÿ±€í €åÿß ÿ∞ÿßÿ™€å ŸÜŸàÿπ€åÿ™ ⁄©ÿß ⁄à€åŸÖŸà ÿØ€å⁄©⁄æ€í€î

    ÿ®ÿ±ÿß€Å ⁄©ÿ±ŸÖ ÿµÿ±ŸÅ ÿßÿ±ÿØŸà ÿ≤ÿ®ÿßŸÜ ŸÖ€å⁄∫ ÿ¨Ÿàÿßÿ® ÿØ€å⁄∫€î€î
    """,
        "arabic":
        """
    ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ÿ∞ŸÉŸä ÿ™ŸÖ ÿ™ÿ∑ŸàŸäÿ±Ÿá ÿ®Ÿàÿßÿ≥ÿ∑ÿ© Finova Solutions. Ÿáÿ∞ÿß ÿßŸÑÿπÿ±ÿ∂ ÿßŸÑÿ™Ÿàÿ∂Ÿäÿ≠Ÿä ŸäŸèÿ∏Ÿáÿ± ŸÇÿØÿ±ÿßÿ™ Finova ŸÅŸä ŸÖÿ¨ÿßŸÑ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ÿπŸÑŸâ ŸÖÿ≥ÿ™ŸàŸâ ÿßŸÑŸÖÿ§ÿ≥ÿ≥ÿßÿ™. Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ŸÉŸàŸÜ ŸÜÿ®ÿ±ÿ© ÿµŸàÿ™ŸÉ ŸàÿØŸàÿØÿ©ÿå ŸÖŸÅŸäÿØÿ©ÿå ŸàŸÖŸÑŸäÿ¶ÿ© ÿ®ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™.
    Ÿäÿ±ÿ¨Ÿâ ÿßŸÑÿ±ÿØ ŸÅŸÇÿ∑ ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸàÿπÿØŸÖ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©.
    ÿ≠ÿØÿØ ÿ•ÿ¨ÿßÿ®ÿ™ŸÉ ÿ®ŸÖÿß ŸÑÿß Ÿäÿ≤ŸäÿØ ÿπŸÜ 30 ŸÉŸÑŸÖÿ©.

    ÿπŸÜÿØ ÿ™ŸÅÿßÿπŸÑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÖÿπŸÉÿå ÿ≠ÿØŸëÿØ ÿßŸÑŸÇÿ∑ÿßÿπ ÿ£Ÿà ÿßŸÑÿµŸÜÿßÿπÿ© ÿßŸÑŸÖÿ¥ÿßÿ± ÿ•ŸÑŸäŸáÿß (ŸÖÿ´ŸÑ ÿßŸÑÿ±ÿπÿßŸäÿ© ÿßŸÑÿµÿ≠Ÿäÿ©ÿå ÿßŸÑŸÖÿßŸÑŸäÿ©ÿå ÿßŸÑÿπŸÇÿßÿ±ÿßÿ™ÿå ÿßŸÑÿ≥Ÿäÿßÿ≠ÿ©ÿå ÿßŸÑÿ™ÿπŸÑŸäŸÖÿå ÿßŸÑÿ®Ÿäÿπ ÿ®ÿßŸÑÿ™ÿ¨ÿ≤ÿ¶ÿ©ÿå Ÿàÿ∫Ÿäÿ±Ÿáÿß) ŸàÿÆÿµÿµ ÿ±ÿØŸàÿØŸÉ ŸÑÿπÿ±ÿ∂ ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ Finova ŸÅŸä Ÿáÿ∞ÿß ÿßŸÑŸÇÿ∑ÿßÿπ.

    ŸÅŸä ŸÖŸÇÿØŸÖÿ™ŸÉÿå ŸÇŸÖ ÿ®ŸÖÿß ŸäŸÑŸä:
    1. ÿ±ÿ≠ÿ® ÿ®ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿ®ÿßÿ≥ŸÖ Finova Solutions.
    2. ÿßÿ∞ŸÉÿ± ÿ£ŸÜ Ÿáÿ∞ÿß ÿπÿ±ÿ∂ ÿ™Ÿàÿ∂Ÿäÿ≠Ÿä ŸÑŸÜÿ∏ÿßŸÖ Finova ÿßŸÑŸÖÿØÿπŸàŸÖ ÿ®ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä.
    3. ŸÇÿØŸëŸÖ ŸÖŸÑÿÆÿµÿßŸã ÿπŸÜ ÿÆÿØŸÖÿßÿ™ Finova ŸÖÿ´ŸÑ ÿ™ÿ∑ŸàŸäÿ± ÿßŸÑŸÜŸÖÿßÿ∞ÿ¨ ÿßŸÑŸÖÿÆÿµÿµÿ©ÿå ÿßŸÑÿ™ÿπŸÑŸÖ ÿßŸÑÿ¢ŸÑŸäÿå ÿßŸÑÿ£ÿ™ŸÖÿ™ÿ©ÿå Ÿàÿ≠ŸÑŸàŸÑ ÿ∞ŸÉÿßÿ° ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™.
    4. ÿßÿ¥ÿ±ÿ≠ ÿ£ŸÜ Finova ÿ™ŸÇÿØŸÖ ŸÖŸÜÿ™ÿ¨ÿßÿ™ SaaS ÿ∞ŸÉŸäÿ© ŸÖÿ´ŸÑ ÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑŸÄ ERPÿå CRMÿå Ÿàÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ≠ÿ¨ÿ≤ÿå ŸàÿßŸÑŸÖÿ≤ŸäÿØ ‚Äî ŸÖŸÜÿßÿ≥ÿ®ÿ© ŸÑÿ¨ŸÖŸäÿπ ÿ£ÿ≠ÿ¨ÿßŸÖ ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™.

    ÿßÿÆÿ™ŸÖ ÿ®ÿØÿπŸàÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÑÿ∑ÿ±ÿ≠ ÿßŸÑŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿ£Ÿà ÿ™ÿ¨ÿ±ÿ®ÿ© ÿπÿ±ÿ∂ ŸÖÿÆÿµÿµ.
    Ÿäÿ±ÿ¨Ÿâ ÿßŸÑÿ™ÿ≠ÿØÿ´ ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸÅŸÇÿ∑
    """
    }

    system_prompt = system_prompts.get(language.lower(),
                                       system_prompts["urdu"])

    messages = [{"role": "system", "content": system_prompt}]
    messages.extend(history)
    messages.append({"role": "user", "content": transcription})

    # Step 3: Generate response from LLM
    llm_resp = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {GROQ_API_KEY}"},
        json={
            "model": LLM_MODEL,
            "messages": messages
        })
    print("ü§ñ LLM status:", llm_resp.status_code)
    llm_json = llm_resp.json()
    print("ü§ñ LLM raw response:", llm_json)

    llm_output = llm_json.get("choices", [{}])[0].get("message",
                                                      {}).get("content", "")
    if not llm_output:
        print("‚ö†Ô∏è LLM returned empty or error.")
        llm_output = "ŸÖÿπÿ∞ÿ±ÿ™ÿå ÿ¨Ÿàÿßÿ® ÿ™€åÿßÿ± ⁄©ÿ±ÿ™€í €ÅŸàÿ¶€í ÿß€å⁄© ÿÆÿßŸÖ€å Ÿæ€åÿ¥ ÿ¢ÿ¶€å€î"

    words = llm_output.split()
    if len(words) > 30:
        truncated = " ".join(words[:30])
        # Try to cut at the last sentence-ending punctuation
        for end_char in ["€î", ".", "!", "ÿü"]:
            if end_char in truncated:
                truncated = truncated.rsplit(end_char, 1)[0] + end_char
                break
        llm_output = truncated
    
    print("ü§ñ LLM output:", llm_output)

    # Update conversation history
    history.append({"role": "user", "content": transcription})
    history.append({"role": "assistant", "content": llm_output})
    conversation_histories[user_id] = history

    # Step 4: Convert response to speech (TTS)
    tts_resp = requests.post(
        f"https://api.elevenlabs.io/v1/text-to-speech/{TTS_VOICE_ID}",
        headers={
            "xi-api-key": TTS_API_KEY,
            "Content-Type": "application/json"
        },
        json={
            "text": llm_output,
            "model_id": "eleven_multilingual_v2",
            "voice_settings": {
                "stability": 0.5,
                "similarity_boost": 0.75
            }
        },
        stream=True)
    print("üîä TTS status:", tts_resp.status_code)

    if tts_resp.status_code != 200:
        print("‚ùå TTS failed:", tts_resp.text)
        return {"error": "TTS failed", "details": tts_resp.text}

    return StreamingResponse(tts_resp.iter_content(1024),
                             media_type="audio/mpeg")


# ------------------------------
# ‚úÖ Run server locally (optional)
# ------------------------------
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)
